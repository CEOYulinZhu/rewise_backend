"""
å›æ”¶æèµ æ€»åè°ƒå™¨Agentæµ‹è¯•

æµ‹è¯•åè°ƒå™¨Agentçš„å„ç§åŠŸèƒ½ï¼ŒåŒ…æ‹¬å¹¶è¡Œ/ä¸²è¡Œå¤„ç†ã€é”™è¯¯å¤„ç†ç­‰
"""

import asyncio
import json
import logging
import time
import sys
from pathlib import Path
from typing import Dict, Any

import pytest

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from app.agents.recycling_coordinator import RecyclingCoordinatorAgent
from app.core.logger import app_logger
from app.models.recycling_coordinator_models import RecyclingCoordinatorResponse


def print_separator(title: str, width: int = 80):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "=" * width)
    print(f" {title} ".center(width))
    print("=" * width)


def print_subsection(title: str, width: int = 60):
    """æ‰“å°å­ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "-" * width)
    print(f" {title} ".center(width))
    print("-" * width)


def print_json(data: Any, title: str = None):
    """æ ¼å¼åŒ–æ‰“å°JSONæ•°æ®"""
    if title:
        print(f"\nã€{title}ã€‘")
    print(json.dumps(data, ensure_ascii=False, indent=2))


def print_ai_recommendation_process(platform_recommendation):
    """æ‰“å°AIæ¨èè¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯"""
    if not platform_recommendation or not platform_recommendation.success:
        return
    
    print_subsection("AIæ¨èè¿‡ç¨‹è¯¦ç»†åˆ†æ")
    
    # 1. RAGæ£€ç´¢é˜¶æ®µ
    if platform_recommendation.rag_metadata:
        metadata = platform_recommendation.rag_metadata
        print("ğŸ” ç¬¬ä¸€é˜¶æ®µ: RAGçŸ¥è¯†æ£€ç´¢")
        print(f"  æ£€ç´¢åˆ°å€™é€‰å¹³å°: {metadata.get('total_results', 0)}ä¸ª")
        print(f"  ç›¸ä¼¼åº¦é˜ˆå€¼: {metadata.get('similarity_threshold', 0)}")
        print(f"  æ£€ç´¢æ¨¡å¼: {metadata.get('search_mode', 'unknown')}")
    
    # 2. å¹³å°è¯¦ç»†æ•°æ®
    if platform_recommendation.platform_details:
        print(f"\nğŸ“Š ç¬¬äºŒé˜¶æ®µ: å¹³å°åŸºç¡€æ•°æ®åŠ è½½")
        print(f"  åŠ è½½å¹³å°è¯¦ç»†æ•°æ®: {len(platform_recommendation.platform_details)}ä¸ª")
        for i, platform in enumerate(platform_recommendation.platform_details, 1):
            print(f"    {i}. {platform.get('platform_name', 'N/A')}")
            print(f"       ç±»åˆ«åŒ¹é…: {platform.get('focus_categories', [])}")
            print(f"       ç‰¹è‰²æ ‡ç­¾: {platform.get('tags', [])}")
    
    # 3. AIæ¨èç”Ÿæˆ
    if platform_recommendation.ai_recommendations:
        recommendations = platform_recommendation.ai_recommendations.recommendations
        print(f"\nğŸ¤– ç¬¬ä¸‰é˜¶æ®µ: AIæ™ºèƒ½æ¨èç”Ÿæˆ")
        print(f"  ç”Ÿæˆä¸ªæ€§åŒ–æ¨è: {len(recommendations)}ä¸ª")
        
        for i, rec in enumerate(recommendations, 1):
            print(f"\n    æ¨è {i}: {rec.platform_name}")
            print(f"    â”œâ”€ é€‚åˆåº¦è¯„åˆ†: {rec.suitability_score}/10")
            print(f"    â”œâ”€ ä¼˜åŠ¿åˆ†æ ({len(rec.pros)}é¡¹): {rec.pros}")
            print(f"    â”œâ”€ åŠ£åŠ¿åˆ†æ ({len(rec.cons)}é¡¹): {rec.cons}")
            print(f"    â””â”€ æ¨èç†ç”±é•¿åº¦: {len(rec.recommendation_reason)}å­—ç¬¦")
            
            # åˆ†ææ¨èç†ç”±çš„å…³é”®è¯
            reason = rec.recommendation_reason.lower()
            keywords = []
            if 'ç”¨æˆ·' in reason:
                keywords.append('ç”¨æˆ·ç¾¤ä½“')
            if 'äº¤æ˜“' in reason:
                keywords.append('äº¤æ˜“ä¾¿åˆ©')
            if 'ä»·æ ¼' in reason or 'è´¹ç”¨' in reason:
                keywords.append('ä»·æ ¼å› ç´ ')
            if 'ä¿éšœ' in reason or 'éªŒè¯' in reason:
                keywords.append('æœåŠ¡ä¿éšœ')
            if 'ä¸“ä¸š' in reason:
                keywords.append('ä¸“ä¸šæ€§')
            
            if keywords:
                print(f"       æ¨èç†ç”±å…³é”®å› ç´ : {', '.join(keywords)}")
    
    # 4. AIåŸå§‹å“åº”åˆ†æ
    if platform_recommendation.ai_raw_response:
        raw_response = platform_recommendation.ai_raw_response
        print(f"\nğŸ”¤ ç¬¬å››é˜¶æ®µ: AIå“åº”è§£æ")
        print(f"  åŸå§‹å“åº”é•¿åº¦: {len(raw_response)}å­—ç¬¦")
        
        # åˆ†æå“åº”æ ¼å¼
        if '```json' in raw_response:
            print("  å“åº”æ ¼å¼: JSONä»£ç å—æ ¼å¼")
        elif raw_response.strip().startswith('{'):
            print("  å“åº”æ ¼å¼: çº¯JSONæ ¼å¼")
        else:
            print("  å“åº”æ ¼å¼: æ–‡æœ¬æ ¼å¼")
        
        # æ£€æŸ¥JSONç»“æ„
        if '"recommendations"' in raw_response:
            print("  âœ… åŒ…å«æ¨èç»“æ„")
        if '"platform_name"' in raw_response:
            print("  âœ… åŒ…å«å¹³å°åç§°")
        if '"suitability_score"' in raw_response:
            print("  âœ… åŒ…å«é€‚åˆåº¦è¯„åˆ†")
        if '"pros"' in raw_response and '"cons"' in raw_response:
            print("  âœ… åŒ…å«ä¼˜åŠ£åŠ¿åˆ†æ")
        if '"recommendation_reason"' in raw_response:
            print("  âœ… åŒ…å«æ¨èç†ç”±")


def print_location_recommendations(location_recommendation):
    """æ‰“å°åœ°ç‚¹æ¨èè¯¦æƒ…"""
    if not location_recommendation:
        print("âŒ æ— åœ°ç‚¹æ¨èæ•°æ®")
        return
    
    print_subsection("å›æ”¶åœ°ç‚¹æ¨èè¯¦æƒ…")
    print(f"âœ… æ¨èæˆåŠŸ: {location_recommendation.success}")
    print(f"ğŸ“ å›æ”¶ç±»å‹: {location_recommendation.recycling_type}")
    print(f"ğŸ  åœ°ç‚¹æ•°é‡: {len(location_recommendation.locations)}")
    
    if location_recommendation.error:
        print(f"âŒ é”™è¯¯ä¿¡æ¯: {location_recommendation.error}")
    
    # æ˜¾ç¤ºå‰5ä¸ªåœ°ç‚¹
    if location_recommendation.locations:
        print("\næ¨èå›æ”¶åœ°ç‚¹ (å‰5ä¸ª):")
        for i, location in enumerate(location_recommendation.locations[:5], 1):
            distance_text = f"{location.distance_meters}ç±³" if location.distance_meters else "è·ç¦»æœªçŸ¥"
            print(f"{i}. {location.name}")
            print(f"   åœ°å€: {location.address}")
            print(f"   è·ç¦»: {distance_text}")
            if location.tel:
                print(f"   ç”µè¯: {location.tel}")
            print()


def print_platform_recommendations(platform_recommendation):
    """æ‰“å°å¹³å°æ¨èè¯¦æƒ…"""
    if not platform_recommendation:
        print("âŒ æ— å¹³å°æ¨èæ•°æ®")
        return
    
    print_subsection("å¹³å°æ¨èè¯¦æƒ…")
    print(f"âœ… æ¨èæˆåŠŸ: {platform_recommendation.success}")
    
    if platform_recommendation.error:
        print(f"âŒ é”™è¯¯ä¿¡æ¯: {platform_recommendation.error}")
        return
    
    # æ‰“å°AIæ¨èç»“æœ
    if platform_recommendation.ai_recommendations:
        recommendations = platform_recommendation.ai_recommendations.recommendations
        print(f"ğŸª AIæ¨èå¹³å°æ•°é‡: {len(recommendations)}")
        
        print("\nğŸ¤– AIæ¨èå¹³å°è¯¦æƒ…:")
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. ã€{rec.platform_name}ã€‘ (é€‚åˆåº¦è¯„åˆ†: {rec.suitability_score}/10)")
            print(f"     âœ… ä¼˜åŠ¿: {', '.join(rec.pros)}")
            print(f"     âŒ åŠ£åŠ¿: {', '.join(rec.cons)}")
            print(f"     ğŸ’¡ æ¨èç†ç”±: {rec.recommendation_reason}")
            print()
    
    # æ‰“å°å¹³å°è¯¦ç»†æ•°æ®
    if platform_recommendation.platform_details:
        print("ğŸ“Š æ¨èå¹³å°è¯¦ç»†æ•°æ®:")
        for i, platform in enumerate(platform_recommendation.platform_details, 1):
            print(f"  {i}. å¹³å°: {platform.get('platform_name', 'N/A')}")
            print(f"     å›¾æ ‡: {platform.get('platform_icon', 'N/A')}")
            print(f"     æè¿°: {platform.get('description', 'N/A')}")
            print(f"     ä¸»è¦å“ç±»: {', '.join(platform.get('focus_categories', []))}")
            print(f"     å¹³å°ç‰¹è‰²: {', '.join(platform.get('tags', []))}")
            print(f"     äº¤æ˜“æ¨¡å¼: {platform.get('transaction_model', 'N/A')}")
            
            # ç”¨æˆ·æ•°æ®
            user_data = platform.get('user_data', {})
            if user_data:
                print(f"     ç”¨æˆ·æ•°æ®:")
                for key, value in user_data.items():
                    print(f"       {key}: {value}")
            
            # ç”¨æˆ·è¯„åˆ†
            rating = platform.get('rating', {})
            if rating:
                print(f"     ç”¨æˆ·è¯„åˆ†:")
                for store, score in rating.items():
                    print(f"       {store}: {score}")
            print()
    
    # æ˜¾ç¤ºRAGå…ƒæ•°æ®
    if platform_recommendation.rag_metadata:
        print("ğŸ” RAGæ£€ç´¢å…ƒæ•°æ®:")
        metadata = platform_recommendation.rag_metadata
        print(f"  æ£€ç´¢ç»“æœæ€»æ•°: {metadata.get('total_results', 0)}")
        print(f"  ç›¸ä¼¼åº¦é˜ˆå€¼: {metadata.get('similarity_threshold', 0)}")
        print(f"  æœç´¢æ¨¡å¼: {metadata.get('search_mode', 'unknown')}")
    
    # æ‰“å°AIåŸå§‹å“åº”ï¼ˆå¦‚æœæœ‰ï¼‰
    if platform_recommendation.ai_raw_response:
        print("\nğŸ”¤ AIæ¨¡å‹åŸå§‹å“åº” (æˆªå–å‰200å­—ç¬¦):")
        raw_response = platform_recommendation.ai_raw_response
        preview = raw_response[:200] + "..." if len(raw_response) > 200 else raw_response
        print(f"  {preview}")
    
    # æ‰“å°AIæ¨èè¿‡ç¨‹è¯¦ç»†åˆ†æ
    print_ai_recommendation_process(platform_recommendation)


def print_processing_summary(response: RecyclingCoordinatorResponse):
    """æ‰“å°å¤„ç†æ‘˜è¦"""
    print_subsection("å¤„ç†æ‘˜è¦")
    summary = response.get_processing_summary()
    
    print(f"âœ… å¤„ç†æˆåŠŸ: {summary.get('success')}")
    print(f"ğŸ“ åŒ…å«åœ°ç‚¹æ¨è: {summary.get('has_locations')}")
    print(f"ğŸª åŒ…å«å¹³å°æ¨è: {summary.get('has_platforms')}")
    print(f"â™»ï¸ å›æ”¶ç±»å‹: {summary.get('recycling_type', 'æœªçŸ¥')}")
    
    if summary.get('location_count'):
        print(f"ğŸ  åœ°ç‚¹æ€»æ•°: {summary.get('location_count')}")
        print(f"ğŸ“ é™„è¿‘åœ°ç‚¹æ•°: {summary.get('nearby_location_count')}")
    
    if summary.get('platform_count'):
        print(f"ğŸª å¹³å°æ€»æ•°: {summary.get('platform_count')}")
        
        top_platform = summary.get('top_platform')
        if top_platform:
            print(f"â­ æœ€ä½³å¹³å°: {top_platform.get('name')} (è¯„åˆ†: {top_platform.get('score')}/10)")
    
    if response.processing_metadata:
        metadata = response.processing_metadata
        print(f"âš™ï¸ å¤„ç†æ¨¡å¼: {metadata.get('processing_mode')}")
        if metadata.get('processing_time_seconds'):
            print(f"â±ï¸ å¤„ç†è€—æ—¶: {metadata.get('processing_time_seconds')}ç§’")


def print_complete_data_structure(response: RecyclingCoordinatorResponse):
    """æ‰“å°å®Œæ•´çš„æ•°æ®ç»“æ„å’Œæ±‡æ€»æ ¼å¼"""
    print_subsection("å®Œæ•´æ•°æ®ç»“æ„æ±‡æ€»")
    
    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼å¹¶æ‰“å°
    data_dict = response.to_dict()
    
    print("ğŸ“‹ å“åº”æ•°æ®å®Œæ•´ç»“æ„:")
    print_json(data_dict, "åè°ƒå™¨å®Œæ•´å“åº”æ•°æ®")
    
    # æ‰“å°æ•°æ®ç»Ÿè®¡
    print_subsection("æ•°æ®ç»Ÿè®¡ä¿¡æ¯")
    
    # åŸºç¡€ç»Ÿè®¡
    print("ğŸ”¢ åŸºç¡€ç»Ÿè®¡:")
    print(f"  å“åº”çŠ¶æ€: {'âœ… æˆåŠŸ' if response.success else 'âŒ å¤±è´¥'}")
    print(f"  æ•°æ®æ¥æº: {response.source}")
    print(f"  é”™è¯¯ä¿¡æ¯: {response.error or 'æ— '}")
    
    # åœ°ç‚¹æ¨èç»Ÿè®¡
    if response.location_recommendation:
        loc_rec = response.location_recommendation
        print(f"\nğŸ“ åœ°ç‚¹æ¨èç»Ÿè®¡:")
        print(f"  æ¨èæˆåŠŸ: {'âœ…' if loc_rec.success else 'âŒ'}")
        print(f"  å›æ”¶ç±»å‹: {loc_rec.recycling_type or 'æœªè¯†åˆ«'}")
        print(f"  åœ°ç‚¹æ€»æ•°: {len(loc_rec.locations)}")
        
        if loc_rec.locations:
            distances = [loc.distance_meters for loc in loc_rec.locations if loc.distance_meters is not None]
            if distances:
                print(f"  æœ€è¿‘è·ç¦»: {min(distances):.0f}ç±³")
                print(f"  æœ€è¿œè·ç¦»: {max(distances):.0f}ç±³")
                print(f"  å¹³å‡è·ç¦»: {sum(distances)/len(distances):.0f}ç±³")
        
        if loc_rec.search_params:
            search_params = loc_rec.search_params
            print(f"  æœç´¢åŠå¾„: {search_params.get('radius', 0)/1000:.1f}å…¬é‡Œ")
            print(f"  æœç´¢å…³é”®è¯: {search_params.get('keyword', 'N/A')}")
    
    # å¹³å°æ¨èç»Ÿè®¡
    if response.platform_recommendation:
        plat_rec = response.platform_recommendation
        print(f"\nğŸª å¹³å°æ¨èç»Ÿè®¡:")
        print(f"  æ¨èæˆåŠŸ: {'âœ…' if plat_rec.success else 'âŒ'}")
        
        if plat_rec.ai_recommendations:
            recommendations = plat_rec.ai_recommendations.recommendations
            print(f"  AIæ¨èæ•°é‡: {len(recommendations)}")
            
            if recommendations:
                scores = [rec.suitability_score for rec in recommendations]
                print(f"  æœ€é«˜è¯„åˆ†: {max(scores)}/10")
                print(f"  æœ€ä½è¯„åˆ†: {min(scores)}/10")
                print(f"  å¹³å‡è¯„åˆ†: {sum(scores)/len(scores):.1f}/10")
                
                # ç»Ÿè®¡ä¼˜åŠ¿å’ŒåŠ£åŠ¿
                all_pros = []
                all_cons = []
                for rec in recommendations:
                    all_pros.extend(rec.pros)
                    all_cons.extend(rec.cons)
                print(f"  æ€»ä¼˜åŠ¿ç‚¹æ•°: {len(all_pros)}")
                print(f"  æ€»åŠ£åŠ¿ç‚¹æ•°: {len(all_cons)}")
        
        if plat_rec.platform_details:
            print(f"  å¹³å°è¯¦ç»†æ•°æ®: {len(plat_rec.platform_details)}ä¸ª")
        
        if plat_rec.rag_metadata:
            rag_meta = plat_rec.rag_metadata
            print(f"  RAGæ£€ç´¢ç»“æœ: {rag_meta.get('total_results', 0)}ä¸ª")
            print(f"  ç›¸ä¼¼åº¦é˜ˆå€¼: {rag_meta.get('similarity_threshold', 0)}")
    
    # å¤„ç†å…ƒæ•°æ®ç»Ÿè®¡
    if response.processing_metadata:
        metadata = response.processing_metadata
        print(f"\nâš™ï¸ å¤„ç†å…ƒæ•°æ®:")
        print(f"  å¤„ç†æ¨¡å¼: {metadata.get('processing_mode', 'unknown')}")
        
        if metadata.get('processing_time_seconds'):
            processing_time = metadata.get('processing_time_seconds')
            print(f"  æ€»å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        
        # å­æœåŠ¡çŠ¶æ€
        loc_meta = metadata.get('location_recommendation', {})
        plat_meta = metadata.get('platform_recommendation', {})
        
        print(f"  åœ°ç‚¹æ¨èçŠ¶æ€: {'âœ… æˆåŠŸ' if loc_meta.get('success') else 'âŒ å¤±è´¥'}")
        if loc_meta.get('error'):
            print(f"    é”™è¯¯: {loc_meta.get('error')}")
        
        print(f"  å¹³å°æ¨èçŠ¶æ€: {'âœ… æˆåŠŸ' if plat_meta.get('success') else 'âŒ å¤±è´¥'}")
        if plat_meta.get('error'):
            print(f"    é”™è¯¯: {plat_meta.get('error')}")
    
    # æ•°æ®è´¨é‡è¯„ä¼°
    print_subsection("æ•°æ®è´¨é‡è¯„ä¼°")
    
    quality_score = 0
    max_score = 10
    
    # åŸºç¡€æˆåŠŸæ€§ (30%)
    if response.success:
        quality_score += 3
    
    # åœ°ç‚¹æ¨èè´¨é‡ (35%)
    if response.has_location_recommendations():
        quality_score += 2  # åŸºç¡€åˆ†
        loc_count = len(response.location_recommendation.locations)
        if loc_count >= 10:
            quality_score += 1.5  # æ•°é‡å……è¶³
        elif loc_count >= 5:
            quality_score += 1
        
        # è·ç¦»è´¨é‡
        nearby_count = len(response.get_nearby_locations(max_distance_meters=5000))
        if nearby_count > 0:
            quality_score += 1  # æœ‰5å…¬é‡Œå†…çš„åœ°ç‚¹
    
    # å¹³å°æ¨èè´¨é‡ (35%)
    if response.has_platform_recommendations():
        quality_score += 2  # åŸºç¡€åˆ†
        recommendations = response.platform_recommendation.ai_recommendations.recommendations
        if recommendations:
            avg_score = sum(rec.suitability_score for rec in recommendations) / len(recommendations)
            if avg_score >= 8:
                quality_score += 1.5  # é«˜è´¨é‡æ¨è
            elif avg_score >= 6:
                quality_score += 1
            
            # æ¨èç†ç”±è´¨é‡
            if all(len(rec.recommendation_reason) > 20 for rec in recommendations):
                quality_score += 1  # è¯¦ç»†çš„æ¨èç†ç”±
    
    quality_percentage = (quality_score / max_score) * 100
    print(f"ğŸ“Š æ•°æ®è´¨é‡è¯„åˆ†: {quality_score:.1f}/{max_score} ({quality_percentage:.1f}%)")
    
    if quality_percentage >= 80:
        print("   è¯„çº§: â­â­â­ ä¼˜ç§€")
    elif quality_percentage >= 60:
        print("   è¯„çº§: â­â­ è‰¯å¥½")
    elif quality_percentage >= 40:
        print("   è¯„çº§: â­ ä¸€èˆ¬")
    else:
        print("   è¯„çº§: éœ€è¦æ”¹è¿›")


@pytest.mark.asyncio
async def test_complete_coordination():
    """æµ‹è¯•å®Œæ•´åè°ƒåŠŸèƒ½"""
    print_separator("æµ‹è¯•å®Œæ•´åè°ƒåŠŸèƒ½")

    # å‡†å¤‡æµ‹è¯•æ•°æ® - æ¨¡æ‹Ÿåˆ†æç»“æœ
    analysis_result = {
        "category": "ç”µå­äº§å“",
        "sub_category": "æ™ºèƒ½æ‰‹æœº",
        "brand": "è‹¹æœ",
        "condition": "å…«æˆæ–°",
        "description": "iPhone 12ï¼Œä½¿ç”¨ä¸¤å¹´ï¼Œå¤–è§‚è‰¯å¥½ï¼ŒåŠŸèƒ½æ­£å¸¸ï¼Œæœ‰äº›è®¸ç£¨æŸ",
        "keywords": ["æ‰‹æœº", "iPhone", "è‹¹æœ", "ç”µå­äº§å“"],
        "special_features": "Face IDæ­£å¸¸ï¼Œç”µæ± å¥åº·åº¦85%"
    }
    
    # æ¨¡æ‹Ÿç”¨æˆ·ä½ç½® (åŒ—äº¬å¸‚æœé˜³åŒº)
    user_location = "116.447303,39.906823"
    
    print("ğŸ” è¾“å…¥åˆ†æç»“æœ:")
    print_json(analysis_result)
    print(f"ğŸ“ ç”¨æˆ·ä½ç½®: {user_location}")

    async with RecyclingCoordinatorAgent() as coordinator:
        print("\nğŸš€ å¼€å§‹åè°ƒå›æ”¶æèµ æ¨è...")
        start_time = time.time()

        # æµ‹è¯•å¹¶è¡Œæ¨¡å¼
        print("\nã€å¹¶è¡Œå¤„ç†æ¨¡å¼ã€‘")
        result = await coordinator.coordinate_recycling_donation(
            analysis_result=analysis_result,
            user_location=user_location,
            radius=30000,  # 30å…¬é‡Œæœç´¢åŠå¾„
            max_locations=15,  # æœ€å¤š15ä¸ªåœ°ç‚¹
            enable_parallel=True
        )

        end_time = time.time()
        processing_time = end_time - start_time

        print(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        print(f"âœ… åè°ƒç»“æœ: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
        
        if result.success:
            # æ‰“å°å¤„ç†æ‘˜è¦
            print_processing_summary(result)
            
            # æ‰“å°åœ°ç‚¹æ¨è
            print_location_recommendations(result.location_recommendation)
            
            # æ‰“å°å¹³å°æ¨è
            print_platform_recommendations(result.platform_recommendation)
            
            # æ‰“å°å®Œæ•´æ•°æ®ç»“æ„å’Œæ±‡æ€»
            print_complete_data_structure(result)
            
        else:
            print(f"âŒ é”™è¯¯ä¿¡æ¯: {result.error}")
            # å³ä½¿å¤±è´¥ä¹Ÿæ‰“å°æ•°æ®ç»“æ„ä»¥ä¾¿è°ƒè¯•
            print_complete_data_structure(result)


@pytest.mark.asyncio
async def test_serial_vs_parallel():
    """æµ‹è¯•ä¸²è¡Œä¸å¹¶è¡Œå¤„ç†æ¨¡å¼å¯¹æ¯”"""
    print_separator("æµ‹è¯•ä¸²è¡Œä¸å¹¶è¡Œå¤„ç†æ¨¡å¼å¯¹æ¯”")

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    analysis_result = {
        "category": "å®¶ç”¨ç”µå™¨",
        "sub_category": "ç”µè§†",
        "brand": "å°ç±³",
        "condition": "ä¸ƒæˆæ–°",
        "description": "55å¯¸æ™ºèƒ½ç”µè§†ï¼Œä½¿ç”¨ä¸‰å¹´ï¼Œç”»è´¨æ¸…æ™°ï¼Œé¥æ§å™¨é½å…¨",
        "keywords": ["ç”µè§†", "å®¶ç”µ", "æ™ºèƒ½ç”µè§†"],
        "special_features": "4Kåˆ†è¾¨ç‡ï¼Œæ”¯æŒHDR"
    }
    
    user_location = "121.473701,31.230416"  # ä¸Šæµ·å¸‚é»„æµ¦åŒº
    
    async with RecyclingCoordinatorAgent() as coordinator:
        
        # æµ‹è¯•ä¸²è¡Œæ¨¡å¼
        print_subsection("ä¸²è¡Œå¤„ç†æ¨¡å¼")
        start_time = time.time()
        
        serial_result = await coordinator.coordinate_recycling_donation(
            analysis_result=analysis_result,
            user_location=user_location,
            enable_parallel=False
        )
        
        serial_time = time.time() - start_time
        print(f"â±ï¸ ä¸²è¡Œå¤„ç†æ—¶é—´: {serial_time:.2f} ç§’")
        print(f"âœ… ä¸²è¡Œå¤„ç†ç»“æœ: {'æˆåŠŸ' if serial_result.success else 'å¤±è´¥'}")
        
        # æµ‹è¯•å¹¶è¡Œæ¨¡å¼
        print_subsection("å¹¶è¡Œå¤„ç†æ¨¡å¼")
        start_time = time.time()
        
        parallel_result = await coordinator.coordinate_recycling_donation(
            analysis_result=analysis_result,
            user_location=user_location,
            enable_parallel=True
        )
        
        parallel_time = time.time() - start_time
        print(f"â±ï¸ å¹¶è¡Œå¤„ç†æ—¶é—´: {parallel_time:.2f} ç§’")
        print(f"âœ… å¹¶è¡Œå¤„ç†ç»“æœ: {'æˆåŠŸ' if parallel_result.success else 'å¤±è´¥'}")
        
        # æ€§èƒ½å¯¹æ¯”
        print_subsection("æ€§èƒ½å¯¹æ¯”")
        if serial_time > 0 and parallel_time > 0:
            speedup = serial_time / parallel_time
            print(f"âš¡ æ€§èƒ½æå‡: {speedup:.2f}x")
            print(f"â±ï¸ æ—¶é—´èŠ‚çœ: {(serial_time - parallel_time):.2f} ç§’")
        
        # ç»“æœä¸€è‡´æ€§æ£€æŸ¥
        print_subsection("ç»“æœä¸€è‡´æ€§æ£€æŸ¥")
        both_success = serial_result.success and parallel_result.success
        print(f"âœ… ä¸¤ç§æ¨¡å¼éƒ½æˆåŠŸ: {both_success}")
        
        if both_success:
            # æ¯”è¾ƒå›æ”¶ç±»å‹
            serial_type = serial_result.get_recycling_type()
            parallel_type = parallel_result.get_recycling_type()
            print(f"â™»ï¸ å›æ”¶ç±»å‹ä¸€è‡´: {serial_type == parallel_type} ({serial_type} vs {parallel_type})")
            
            # æ¯”è¾ƒåœ°ç‚¹æ•°é‡
            serial_locations = len(serial_result.get_nearby_locations()) if serial_result.has_location_recommendations() else 0
            parallel_locations = len(parallel_result.get_nearby_locations()) if parallel_result.has_location_recommendations() else 0
            print(f"ğŸ“ é™„è¿‘åœ°ç‚¹æ•°: ä¸²è¡Œ{serial_locations}ä¸ª, å¹¶è¡Œ{parallel_locations}ä¸ª")
            
            # æ¯”è¾ƒå¹³å°æ¨è
            serial_has_platforms = serial_result.has_platform_recommendations()
            parallel_has_platforms = parallel_result.has_platform_recommendations()
            print(f"ğŸª å¹³å°æ¨èä¸€è‡´: {serial_has_platforms == parallel_has_platforms}")
            
            # è¯¦ç»†å¯¹æ¯”å¹³å°æ¨èç»“æœ
            if serial_has_platforms and parallel_has_platforms:
                serial_platforms = [rec.platform_name for rec in serial_result.platform_recommendation.ai_recommendations.recommendations]
                parallel_platforms = [rec.platform_name for rec in parallel_result.platform_recommendation.ai_recommendations.recommendations]
                print(f"ğŸª æ¨èå¹³å°åç§°: ä¸²è¡Œ{serial_platforms}, å¹¶è¡Œ{parallel_platforms}")
                print(f"ğŸª å¹³å°åç§°ä¸€è‡´: {set(serial_platforms) == set(parallel_platforms)}")
        
        # æ‰“å°ä¸²è¡Œæ¨¡å¼è¯¦ç»†ç»“æœ
        print_subsection("ä¸²è¡Œæ¨¡å¼è¯¦ç»†ç»“æœ")
        if serial_result.success:
            print("âœ… ä¸²è¡Œæ¨¡å¼æ‰§è¡ŒæˆåŠŸ")
            print_complete_data_structure(serial_result)
        else:
            print("âŒ ä¸²è¡Œæ¨¡å¼æ‰§è¡Œå¤±è´¥")
            print(f"é”™è¯¯ä¿¡æ¯: {serial_result.error}")
        
        # æ‰“å°å¹¶è¡Œæ¨¡å¼è¯¦ç»†ç»“æœ  
        print_subsection("å¹¶è¡Œæ¨¡å¼è¯¦ç»†ç»“æœ")
        if parallel_result.success:
            print("âœ… å¹¶è¡Œæ¨¡å¼æ‰§è¡ŒæˆåŠŸ")
            print_complete_data_structure(parallel_result)
        else:
            print("âŒ å¹¶è¡Œæ¨¡å¼æ‰§è¡Œå¤±è´¥")
            print(f"é”™è¯¯ä¿¡æ¯: {parallel_result.error}")


@pytest.mark.asyncio
async def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print_separator("æµ‹è¯•é”™è¯¯å¤„ç†")

    async with RecyclingCoordinatorAgent() as coordinator:
        
        # æµ‹è¯•æ— æ•ˆåˆ†æç»“æœ
        print_subsection("æµ‹è¯•æ— æ•ˆåˆ†æç»“æœ")
        result = await coordinator.coordinate_recycling_donation(
            analysis_result=None,
            user_location="116.447303,39.906823"
        )
        print(f"âŒ ç©ºåˆ†æç»“æœå¤„ç†: {'âœ“ æ­£ç¡®æ‹’ç»' if not result.success else 'âœ— åº”è¯¥å¤±è´¥'}")
        if not result.success:
            print(f"é”™è¯¯ä¿¡æ¯: {result.error}")
        
        # æµ‹è¯•æ— æ•ˆä½ç½®
        print_subsection("æµ‹è¯•æ— æ•ˆç”¨æˆ·ä½ç½®")
        result = await coordinator.coordinate_recycling_donation(
            analysis_result={"category": "ç”µå­äº§å“", "description": "æµ‹è¯•ç‰©å“"},
            user_location=""
        )
        print(f"âŒ ç©ºä½ç½®å¤„ç†: {'âœ“ æ­£ç¡®æ‹’ç»' if not result.success else 'âœ— åº”è¯¥å¤±è´¥'}")
        if not result.success:
            print(f"é”™è¯¯ä¿¡æ¯: {result.error}")


@pytest.mark.asyncio 
async def test_component_status():
    """æµ‹è¯•ç»„ä»¶çŠ¶æ€"""
    print_separator("æµ‹è¯•ç»„ä»¶çŠ¶æ€")

    coordinator = RecyclingCoordinatorAgent()
    
    # æµ‹è¯•åˆå§‹çŠ¶æ€
    initial_status = coordinator.get_component_status()
    print("åˆå§‹ç»„ä»¶çŠ¶æ€:")
    print_json(initial_status)
    
    # åˆå§‹åŒ–åçŠ¶æ€
    await coordinator._ensure_initialized()
    initialized_status = coordinator.get_component_status()
    print("\nåˆå§‹åŒ–åç»„ä»¶çŠ¶æ€:")
    print_json(initialized_status)
    
    # æ¸…ç†èµ„æº
    await coordinator.close()
    final_status = coordinator.get_component_status()
    print("\næ¸…ç†åç»„ä»¶çŠ¶æ€:")
    print_json(final_status)


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print_separator("å›æ”¶æèµ æ€»åè°ƒå™¨Agentæµ‹è¯•å¼€å§‹", 100)
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.basicConfig(level=logging.INFO)
    app_logger.setLevel(logging.INFO)
    
    try:
        # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
        await test_complete_coordination()
        
        # æ€§èƒ½å¯¹æ¯”æµ‹è¯•
        await test_serial_vs_parallel()
        
        # é”™è¯¯å¤„ç†æµ‹è¯•
        await test_error_handling()
        
        # ç»„ä»¶çŠ¶æ€æµ‹è¯•
        await test_component_status()
        
        print_separator("æ‰€æœ‰æµ‹è¯•å®Œæˆ", 100)
        print("âœ… æµ‹è¯•æ‰§è¡Œå®Œæ¯•ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹ç»“æœ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 