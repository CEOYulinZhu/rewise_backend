## **“闲置物语” 后端系统设计文档 (V2.1 - 最终完整版)**

### 1. 项目概述

本文档旨在阐述“闲置物语”Web应用的后端系统架构和技术实现方案。该后端系统旨在接收用户上传的闲置物品信息（支持图片、文字、图片+文字三种模式），通过一个集成了多模态大模型（LLM）、实时爬虫和自有知识库（通过RAG技术）的智能体，为用户提供处置方案。

系统交互分为两个层面：
1.  **实时进度反馈**: 在处理过程中，后端会持续向前端反馈当前任务的进度，提升用户体验。
2.  **两阶段结果呈现**: 最终结果分为“概览页”和“详情页”，满足用户从宏观到微观的浏览需求。
    *   **概览页**: 快速生成三大处置路径（创意改造、回收/捐赠、二手交易）的推荐度和核心理由标签。
    *   **详情页**: 为每个路径生成一个结构化、数据驱动、可操作性强的详细报告。

### 2. 系统架构

系统采用基于**事件驱动**和**异步任务处理**的现代化架构。Web服务（FastAPI）与高延迟的AI/爬虫任务（Celery）完全解耦，并通过实时状态更新机制，为前端提供流畅的进度反馈。

#### 2.1 架构图

```
+-----------+       (1) API Request      +------------------+  (2) Task via Redis   +-----------------+
|  前端应用  |--------------------------->|      FastAPI     |---------------------->|      Redis      |
|  (Client) |<---------------------------|  (API Gateway)   |<----------------------| (Message Broker |
|           | (3) Poll for Progress/Result +-----+---------+                       |      & Cache)   |
+-----------+                                  |                                 +--------+--------+
                                               | DB Write/Read                              |
                                       +-------v--------+                           (4) Process Task
                                       |  PostgreSQL    |                       +---------v---------+
                                       | (JSONB-centric)|                       |   Celery Worker   |
                                       +----------------+                       +----+--------------+
                                                                                     | (Updates own state in Redis)
                                                                                     |
                                                                           +---------v---------+
                                                                           | Hierarchical Agent  |
                                                                           +---------+---------+
                                                                          (Tools)|           |(Tools)
                                   +-----------------+<--------------------------+           +------------->+-----------------+
                                   |  RAG Retriever  |                         |           |                |  Real-time      |
                                   | (ChromaDB)      |                         |           |                |  Crawler (httpx)|
                                   +-----------------+                 +-------v-------+   +-------v-------+  +-----------------+
                                                                     | Multi-Modal   |   | Generation    |
                                                                     | LLM (蓝心)    |   | LLM (蓝心)    |
                                                                     +---------------+   +---------------+
```

### 3. 技术栈

*   **语言**: Python 3.12
*   **框架**: FastAPI, Celery
*   **AI核心**: LangChain, 蓝心大模型API
*   **爬虫**: `httpx` (API逆向)
*   **数据库**: PostgreSQL (大量使用`JSONB`字段), ChromaDB (向量库), Redis (消息/缓存/任务状态后端)
*   **部署**: Docker, Gunicorn, Nginx（开发完再考虑）

### 4. 核心工作流程

#### 4.1 任务生命周期与实时反馈

为了提供流畅的用户体验，整个后端任务处理流程都支持**分步状态更新**。

1.  **任务创建**: 用户通过FastAPI提交请求，系统立即返回一个`task_id`。
2.  **进度轮询**: 前端使用此`task_id`，以1-2秒的频率轮询任务状态接口。
3.  **状态更新**: Celery Worker在执行长任务的每个关键步骤时，都会更新该任务在Redis中的状态和进度描述。
4.  **结果获取**: 前端通过轮询接口获取到这些实时更新的进度信息并展示给用户。当任务最终完成时，接口会返回`SUCCESS`状态和完整的JSON结果。

**Celery Worker执行流程示例 (含状态更新):**
1.  **任务开始**: Worker从Redis获取任务。
2.  **步骤1 - 物品识别**:
    *   **更新状态**: 调用`task.update_state(state='PROGRESS', meta={'step': 1, 'message': '正在识别您的物品...'})`。
    *   执行蓝心视觉模型调用。
3.  **步骤2 - 路径评估**:
    *   **更新状态**: 调用`task.update_state(state='PROGRESS', meta={'step': 2, 'message': '正在评估处置路径...'})`。
    *   执行三大路径的初步分析。
4.  **步骤3 - 深度处理**:
    *   **更新状态**: 调用`task.update_state(state='PROGRESS', meta={'step': 3, 'message': '正在抓取数据并生成详细建议...'})`。
    *   并行执行RAG检索、实时爬虫等耗时操作。
5.  **步骤4 - 报告汇总**:
    *   **更新状态**: 调用`task.update_state(state='PROGRESS', meta={'step': 4, 'message': '正在汇总您的专属报告...'})`。
    *   调用蓝心大模型生成最终的完整JSON报告。
6.  **任务完成**: 返回最终报告，Celery自动将任务状态更新为`SUCCESS`。

#### 4.2 两阶段结果生成模型

##### **Stage 1: 初步分析与概览生成 (Initial Analysis & Overview Generation)**

1.  **输入与识别 (Input & Recognition)**:
    *   接收用户输入（图片/文字/图文）。
    *   调用`蓝心大模型视觉模型`进行多模态识别，提取核心信息：`{ "item": "旧羊毛衫", "category": "衣物", "condition": "袖口磨损", "material": "羊毛", "color": "米色" }`。

2.  **路径评估 (Path Evaluation)**:
    *   **Agent**将识别出的信息，并行地输入到三个专门的评估“子模块”中：
        *   **改造评估**: 查询`ChromaDB`，判断该物品是否有丰富的、有趣的改造潜力。
        *   **回收评估**: 查询`PostgreSQL`的回收渠道表，判断该物品类别是否易于回收/捐赠。
        *   **交易评估**: **快速**调用二手平台API，对该物品进行初步的价格和流动性判断。
    *   **LLM决策**: Agent将三个子模块的评估结果汇总，交给`蓝心大模型`，让它生成最终的概览数据。

3.  **概览数据结构 (Overview JSON)**:
    ```json
    {
      "overview": {
        "creative_makeover": {
          "recommendation_score": 75,
          "reason_tags": ["旧物新生", "个性化定制", "实用小物", "亲子互动"]
        },
        "recycling_donation": {
          "recommendation_score": 50,
          "reason_tags": ["环保处理", "支持公益", "操作简便"]
        },
        "second_hand_trade": {
          "recommendation_score": 85,
          "reason_tags": ["快速变现", "高需求品类", "市场活跃", "定价空间大"]
        }
      }
    }
    ```

##### **Stage 2: 各路径详情深度生成 (Detailed Report Generation)**

在生成概览后，Agent继续工作，为每个路径生成详细数据。

1.  **创意改造详情 (Creative Makeover Details)**
    *   **RAG深度检索**: 使用更具体的关键词（如“羊毛衫改造”、“旧毛衣DIY”），从`ChromaDB`检索出最匹配的1-2个改造方案。
    *   **LLM方案生成**: 将检索到的改造方案喂给`蓝心大模型`，指令它生成一个结构化的改造方案。
    *   **教程爬取**: **并行地**，触发`httpx`爬虫，根据物品关键词去B站、小红书等抓取3-5个相关教程的元数据。
    *   **数据结构**:
        ```json
        "details": {
          "creative_makeover": {
            "overview": {
              "step_count": 5,
              "estimated_time": "约2小时",
              "difficulty": "中等",
              "budget_range": "0-30元"
            },
            "steps": [
              {
                "title": "第一步：清洗与拆解",
                "description": "将羊毛衫彻底清洗干净，然后小心地从接缝处拆开...",
                "tools": ["剪刀", "拆线器"],
                "difficulty": "简单",
                "time": "30分钟"
              },
              {
                "title": "第二步：设计与裁剪",
                "description": "根据抱枕图纸，在拆开的毛衣片上画出轮廓并裁剪。",
                "tools": ["图纸", "划粉", "剪刀"],
                "difficulty": "中等",
                "time": "30分钟"
              }
            ],
            "tutorials": [
              {
                "title": "【保姆级教程】不穿的毛衣别扔！改成超可爱抱枕",
                "source": "Bilibili",
                "author": "手工达人小喵",
                "link": "https://www.bilibili.com/video/BV1xx4y1z7xx"
              },
              {
                "title": "旧毛衣大改造，简单几步变身温暖手套",
                "source": "小红书",
                "author": "生活小能手",
                "link": "https://www.xiaohongshu.com/explore/xxxxxxxx"
              }
            ]
          }
        }
        ```

2.  **回收/捐赠详情 (Recycling & Donation Details)**
    *   **地理位置处理**: 如果用户提供了地理位置（前端通过浏览器API获取），则优先查询。
    *   **渠道查询**:
        *   **线下**: 在`PostgreSQL`中，根据物品类别和地理位置（若有）查询`recycling_channels`表。
        *   **线上**: 在`PostgreSQL`中查询一个预先整理好的“线上回收平台”表。
    *   **LLM整合**: 将查询到的线上线下渠道信息，交由LLM进行整理和人性化描述。
    *   **数据结构**:
        ```json
        "details": {
          "recycling_donation": {
            "overview": {
              "recycling_points_count": 3,
              "online_platforms_count": 4,
              "operation_difficulty": "简单",
              "executability": "立即"
            },
            "recycling_points": [
              {
                "name": "爱心环保回收站（XX街道店）",
                "distance": "1.2公里",
                "address": "XX市XX区XX路123号",
                "hours": "周一至周五 09:00-18:00",
                "tags": ["衣物", "纺织品"],
                "phone": "123-4567-8901"
              }
            ],
            "online_platforms": [
              {
                "icon_url": "http://.../feiyi.png",
                "name": "飞蚂蚁",
                "description": "提供上门回收旧衣物服务，可兑换环保商品。",
                "tags": ["免费上门", "环保积分"],
                "user_count": "1000万+",
                "rating": 4.8
              }
            ]
          }
        }
        ```

3.  **二手平台交易详情 (Second-hand Trade Details)**
    *   **深度爬虫**: Agent触发`httpx`爬虫，**并行地**向闲鱼、转转等目标平台的API发起多次请求，抓取：
        *   **价格区间分析**: 抓取至少50-100条相关商品，统计不同价格区间的已售数量。
        *   **销量分析**: 统计各平台总销量。
        *   **竞争分析**: 分析在售商品数量和价格分布。
    *   **数据分析与LLM生成**:
        *   爬虫返回的原始数据由Python脚本（如Pandas）进行统计分析。
        *   将分析结果和用户物品信息，一并交给`蓝心大模型`。
        *   LLM负责生成所有模块的文案，包括定价建议、竞争分析描述以及最终的销售文案。
    *   **数据结构**:
        ```json
        "details": {
          "second_hand_trade": {
            "summary": {
              "suggested_price": "80-100元",
              "estimated_sale_time": "3-7天",
              "competition_level": "中等",
              "sale_probability": "约65%"
            },
            "analysis": {
              "price_distribution": {
                "platforms": ["闲鱼", "转转", "得物"],
                "data": [
                  { "range": "50-70元", "sales": [15, 10, 5] },
                  { "range": "70-90元", "sales": [25, 18, 12] },
                  { "range": "90-110元", "sales": [12, 8, 9] }
                ]
              },
              "total_sales": {
                "platforms": ["闲鱼", "转转", "得物"],
                "sales": [250, 150, 80]
              },
              "competition_analysis": {
                "distribution": { "low": 20, "medium": 55, "high": 25 },
                "user_position": "中等竞争者",
                "description": "该类商品在平台属于中度竞争，定价合理并优化文案是成交关键。"
              }
            },
            "comparison": [
              {
                "platform_name": "闲鱼",
                "avg_price": "75-95元",
                "avg_sale_time": "2-5天",
                "competition": "中等",
                "link": "https://2.taobao.com/"
              }
            ],
            "copywriting": {
              "title": "9成新米色羊毛衫，仅穿一季，保暖舒适，超值出！",
              "description": "这件米色羊毛衫是去年冬天购入的，材质非常柔软亲肤...由于风格变化现转让给有缘人。袖口有轻微使用痕迹，已拍出细节图，不影响穿着。适合秋冬内搭，百搭神器！"
            }
          }
        }
        ```

### 5. API Endpoint 设计

API设计以任务为中心，一个核心接口即可满足前端从任务创建到获取最终结果的所有需求。

**Base URL**: `/api/v1`

| Endpoint           | Method | 描述                             | Request Body / Params                                        | Success Response (2xx)                                       |
| ------------------ | ------ | -------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| `/tasks`           | `POST` | 创建一个新的物品处理任务         | `{ "image_url"?: "string", "text_description"?: "string", "user_location"?: {"lat": float, "lon": float} }` | `202 Accepted` <br> `{ "task_id": "string" }`                |
| `/tasks/{task_id}` | `GET`  | **获取任务的实时进度或最终结果** | Path Param: `task_id`                                        | **处理中**: `{ "status": "PROGRESS", "progress": { "step": 2, "message": "正在评估处置路径..." } }`<br>**成功**: `{ "status": "SUCCESS", "data": { ... (完整JSON报告) ... } }`<br>**失败**: `{ "status": "FAILED", "error": "错误信息" }`<br>**等待中**: `{ "status": "PENDING" }` |

### 6. 数据库 Schema 设计

`PostgreSQL`的`processing_tasks`表是核心，其`result`字段将存储最终成功的完整JSON报告。中间的进度状态由Celery的任务后端（Redis）管理，不持久化到此主表中。

```sql
-- 首先，确保PostGIS扩展已启用 (在数据库中执行一次)
-- CREATE EXTENSION IF NOT EXISTS postgis;

-- 任务表 (核心)
CREATE TABLE processing_tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- 使用UUID更安全，避免顺序ID被猜测
    status VARCHAR(20) NOT NULL DEFAULT 'PENDING', -- 任务的最终状态: PENDING, SUCCESS, FAILED
    
    -- 输入参数
    input_image_url TEXT,
    input_text_description TEXT,
    input_user_location GEOMETRY(Point, 4326), -- 使用PostGIS扩展存储地理位置, 4326是WGS 84标准
    
    -- 输出结果
    result JSONB, -- 存储包含概览和所有详情的完整JSON，使用JSONB格式以支持索引和高效查询
    
    -- 元数据
    error_message TEXT, -- 如果任务失败，记录错误信息
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP, -- 记录创建时间
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP -- 记录最后更新时间
);

-- 创建一个触发器，在更新时自动修改updated_at时间
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = now();
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_tasks_updated_at
BEFORE UPDATE ON processing_tasks
FOR EACH ROW
EXECUTE FUNCTION update_updated_at_column();


-- 线下回收点/捐赠点信息表
CREATE TABLE recycling_channels (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    category VARCHAR(100) NOT NULL, -- 如：衣物, 电子产品, 书籍, 家具, 综合
    location GEOMETRY(Point, 4326), -- 地理位置，用于空间查询
    address TEXT,
    city VARCHAR(100),
    province VARCHAR(100),
    contact_info TEXT,
    website TEXT,
    operating_hours TEXT, -- 如 "周一至周五 09:00-18:00"
    details TEXT, -- 其他备注信息，如"只接收八成新以上衣物"
    is_active BOOLEAN DEFAULT TRUE,
    source VARCHAR(100) -- 数据来源，如 "官网", "手动录入"
);

-- 为地理位置创建空间索引以加速附近查询
CREATE INDEX idx_recycling_channels_location ON recycling_channels USING GIST (location);


-- 线上回收平台表 (静态数据，由后台系统维护)
CREATE TABLE online_recycling_platforms (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL UNIQUE,
    icon_url TEXT,
    description TEXT,
    tags TEXT[], -- 使用数组类型存储标签，如 '{"免费上门", "环保积分"}'
    user_count_desc VARCHAR(50), -- 如 "1000万+"
    rating NUMERIC(2, 1) CHECK (rating >= 0 AND rating <= 5), -- 评分，带约束
    website TEXT,
    platform_type VARCHAR(50) -- 平台类型，如 "回收", "捐赠", "估价"
);
```
